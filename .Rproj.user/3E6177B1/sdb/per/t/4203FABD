{
    "contents" : "---\ntitle: \"Making the african swine fever (ASF) outbreaks in Europe from the data \nscrapped from the OIE WAHID website\"\nauthor: \"Pavel Vodrážka\"\ndate: \"Thursday, January 15, 2015\"\noutput:\n        html_document:\n                toc: true\n---\n\n### Reason\n\nThe maps that can be obtained from the [OIE WAHID website](http://www.oie.int/wahis_2/public/wahid.php/Diseaseinformation/Diseaseoutbreakmaps) are not aesthetically \npleasing, and can be downloaded only as raster images that are not suitable for \nincluding in print quality publications. Other sources of data and maps of ASF \noutbreaks were not found.\n\n### Obtaining the data\n\nThere is no option to dowload the data or no public data API on the OIE WAHID \nwebsite. Data needs to be scraped from the [\"Immediate notifications and \nFollow-Ups\"](http://www.oie.int/wahis_2/public/wahid.php/Diseaseinformation/Immsummary) part of the site.\n\nWe go all the way from getting the webpages of summaries of immediate \nnotifications and follow-ups for african swine fever for all the years (2005 -- \n2014), extracting the links of the full country reports, getting the full \nreports (immediate notifications), extracting the links of the follow-up \nreports, getting the follow-up reports, and getting and processing data from the \ndowloaded reports.\n\nThe starting page is http://www.oie.int/wahis_2/public/wahid.php/Diseaseinformation/Immsummary. \nWe first need be able to programmatically fill the form on the page and download \nthe resulting summaries. We use functions from the R package \"RHTMLForms\" to \naccomplish this part of the task.\n\n```{r}\nlibrary(RHTMLForms)\nurl <- \"http://www.oie.int/wahis_2/public/wahid.php/Diseaseinformation/Immsummary\"\nforms <- getHTMLFormDescription(url) # RHTMLForms\n```\n\nThe `forms` object now contains the description of the forms on the webpage. \n\n```{r}\nnames(forms)\n```\n\nThere are four forms on the page; after inspecting the page source we know that \nwe are interested in the ``r names(forms)[2]``. We now create a function that \nwill serve to submit the form and retrieve the resulting webpage.\n\n```{r}\nsummaries_fun <- createFunction(forms[[\"diseaseform\"]]) # RHTMLForms\n```\n\nBy inspecting the page source and the forms we figure out the necessary \nparameters to the `fun` function: `disease_id_terrestrial` (`= \"12\"` for african \nswine fever), and `year`. Now we download the yearly summaries of immediate \nnotifications and follow-ups to a directory \"summaries\" that we create in the \nwork directory.\n\n```{r}\nyears <- 2005:2014\ndisease = \"12\"\n\nyears_char <- as.character(years)\nnames(years) <- years_char\nsummaries_dir <- \"summaries\"\ndir.create(summaries_dir)\nsummaries_files <- file.path(summaries_dir,\n                             paste0(years_char,\n                                    \".html\")\n                             )\nsummaries <- sapply(years,\n                    function(x) {\n                            summaries_fun(year = x,\n                                          disease_id_terrestrial = disease)\n                            },\n                    simplify = FALSE)\njunk <- mapply(write,\n               x = summaries,\n               file = summaries_files)\nwrite(format(Sys.time()),\n      file = file.path(summaries_dir,\n                       \"date_downloaded.txt\")\n      )\n```\n\nThe summaries html is also stored in the `summaries` object. We will work with \nthis from now on, the saved html files serve for documentation purposes. Now we \nparse the html.\n\n```{r}\nlibrary(XML)\ndoc <- xmlRoot(htmlTreeParse(summaries[[2]], useInternalNodes = TRUE))\ncountry_list <- xpathSApply(doc, \"//table[@class='Table27']//tr[@class='outbreakdetails']//td[@class='filtrer_tds vacborder outbreak_country']/text()\") # needs to remove trailing chars\ntemp_status_list <- xpathSApply(doc, \"//table[@class='Table27']//tr[@class='outbreakdetails']//td[@class='filtrer_tds vacborder']/text()\")\nstatus_list <- temp_status_list[seq(1, length(temp_resolved_list), by = 8)]\ntemp_date_list <- xpathSApply(doc, \"//table[@class='Table27']//tr[@class='outbreakdetails']//td[@class='filtrer_tds vacborder']/text()\")\ndate_list <- temp_date_list[seq(2, length(temp_date_list), by = 8)]\noutbreak_links_char <- xpathSApply(doc, \"//table[@class='Table27']//tr[@class='outbreakdetails']//td[@class='filtrer_tds vacborder']/a[@href='javascript:;']/@onclick\")\nevent_summary_links_char <- xpathSApply(doc, \"//table[@class='Table27']//tr[@class='outbreakdetails']//td[@class='filtrer_tds vacborder']/a[contains(@href, 'viewsummary')]/@href\")\nfull_report_links_char <- xpathSApply(doc, \"//table[@class='Table27']//tr[@class='outbreakdetails']//td[@class='filtrer_tds vacborder']/a[contains(@href, 'page_refer=MapFullEventReport')]/@href\")\n# \ntest <- getHTMLLinks(summaries[[1]])\ntest1 <- readHTMLTable(test)\ntest2 <- test1[[3]]\n```\n",
    "created" : 1421313406224.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3146537792",
    "id" : "4203FABD",
    "lastKnownWriteTime" : 1421349982,
    "path" : "H:/Dokumenty/Odborné/Práce pro jiné (statistika...)/20150114 PaBa (mapa případů ASF)/ASF_map_R_project/main_document.Rmd",
    "project_path" : "main_document.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_markdown"
}